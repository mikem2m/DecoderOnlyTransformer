# Decoder-Only Transformer: Shakespeare Text Generation
This project implements a decoder-only transformer model inspired by the seminal paper Attention Is All You Need. The model is designed to learn and generate text based on the complete works of William Shakespeare. By leveraging a bigram language model, tokenization, and the attention mechanism, this project demonstrates the powerful text generation capabilities of transformers.

This project is my personal attempt to implement a (very simple) GPT from scratch

Big thanks to Andrej Karpathy's tutorial on this -> [link](https://youtu.be/kCc8FmEb1nY?si=Hl4oqcB-CL34RNvM)
